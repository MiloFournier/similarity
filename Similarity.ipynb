{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading article: 403 Client Error: Forbidden for url: https://www.nytimes.com/2024/09/29/us/north-carolina-helene-relief-damage.html\n",
      "Error downloading article: 403 Client Error: Forbidden for url: https://www.nytimes.com/2024/10/01/science/shipwreck-ghost-ship-pacific-drones.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "from typing import Tuple, Any\n",
    "\n",
    "def download_article(url: str) -> str:\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading article: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_title_and_text(html: str) -> Tuple[str, str]:\n",
    "\n",
    "    article = Article('')\n",
    "    article.set_html(html)\n",
    "    article.parse()\n",
    "    return article.title, article.text\n",
    "\n",
    "def main(url: str) -> Tuple[str, str]:\n",
    "    \n",
    "    html = download_article(url)\n",
    "\n",
    "    if html:\n",
    "        title, text = extract_title_and_text(html)\n",
    "        return title, text\n",
    "    else:\n",
    "        return \"\", \"\"\n",
    "\n",
    "urls = [\n",
    "    \"https://www.nytimes.com/2024/09/29/us/north-carolina-helene-relief-damage.html\",\n",
    "    \"https://www.faz.net/aktuell/wirtschaft/kuenstliche-intelligenz/today-s-ai-can-t-be-trusted-19532136.html\",\n",
    "    \"http://www.chinatoday.com.cn/ctenglish/2018/commentaries/202409/t20240925_800378506.html\",\n",
    "    \"https://english.elpais.com/economy-and-business/2024-09-28/from-the-hermes-heir-to-nicolas-cage-millionaires-who-went-bankrupt.html\",\n",
    "    \"https://insatiable.info/2023/06/30/quels-futur-pour-les-reseaux-sociaux/\",\n",
    "    \"https://actu.fr/auvergne-rhone-alpes/lyon_69123/lyon-le-projet-de-reamenagement-des-quais-les-plus-mortels-pour-les-cyclistes-devoile_61667371.html\",\n",
    "    \"https://www.lesnumeriques.com/intelligence-artificielle/huggingchat-l-ia-generative-au-coeur-de-votre-mac-avec-cette-nouvelle-application-n226761.html\",\n",
    "    \"https://www.lebigdata.fr/nebius-mise-sur-paris-pour-son-nouveau-centre-de-donnees-ia-1-milliard-en-jeu\",\n",
    "    \"https://actu.orange.fr/societe/fait-divers/allo-mon-fils-c-est-maman-grace-a-l-ia-des-escrocs-clonent-la-voix-de-sa-mere-pour-lui-extorquer-de-l-argent-magic-CNT000002fcZQN.html\",\n",
    "    \"https://www.cbnews.fr/digital/image-ia-creation-du-collectif-enthousiastes-87456\",\n",
    "    \"https://www.tradingsat.com/brent-crude-dr-sp-FR0011227370/actualites/brent-crude-dr-sp-et-si-l-intelligence-artificielle-reduisait-a-terme-les-prix-du-petrole-1122826.html\",\n",
    "    \"https://www.journaldunet.com/intelligence-artificielle/1533915-comment-exploiter-notebooklm-l-ovni-ia-experimental-de-google/\",\n",
    "    \"https://www.lemonde.fr/international/article/2024/10/01/israel-mene-des-operations-terrestres-dans-le-sud-du-liban_6340509_3210.html\",\n",
    "    \"https://www.lemonde.fr/politique/article/2024/10/01/greve-du-1-octobre-les-syndicats-veulent-donner-le-tempo-mais-s-attendent-a-une-faible-mobilisation_6340346_823448.html\",\n",
    "    \"https://www.lemonde.fr/societe/article/2024/10/01/derives-des-creches-privees-aurore-berge-confirme-avoir-depose-plainte-pour-diffamation-apres-la-publication-du-livre-enquete-les-ogres_6340515_3224.html\",\n",
    "    \"https://www.lemonde.fr/pixels/article/2024/10/01/j-ai-plaide-coupable-d-avoir-fait-du-journalisme-affirme-julian-assange-au-conseil-de-l-europe_6340588_4408996.html\",\n",
    "    \"https://www.lefigaro.fr/sports/rugby/rugby-16-membres-demissionnent-du-comite-directeur-de-la-ffr-20241001\",\n",
    "    \"https://www.lefigaro.fr/international/dans-ses-memoires-boris-johnson-critique-particulierement-emmanuel-macron-20241001\",\n",
    "    \"https://www.lefigaro.fr/flash-actu/normandie-mort-d-un-jeune-de-17-ans-poignarde-pres-d-une-boite-de-nuit-20240929\",\n",
    "    \"https://www.francetvinfo.fr/monde/usa/ouragan-helene-aux-etats-unis-un-presentateur-meteo-sauve-une-femme-en-direct_6812057.html\",\n",
    "    \"https://www.francetvinfo.fr/sports/foot/ligue-des-champions/arsenal-psg-premier-gros-choc-en-ligue-des-champions-et-premieres-crispations_6810745.html\",\n",
    "    \"https://www.liberation.fr/culture/arts/un-tableau-deniche-dans-une-cave-par-un-brocanteur-italien-en-1962-serait-un-original-de-picasso-20241001_YCBPEC5MCNCNTLQMBKGV5EMXZM/\",\n",
    "    \"https://www.nytimes.com/2024/10/01/science/shipwreck-ghost-ship-pacific-drones.html\"\n",
    "]\n",
    "\n",
    "all_titles = []\n",
    "all_texts = []\n",
    "\n",
    "for url in urls:\n",
    "\n",
    "    title, text = main(url)\n",
    "    all_titles.append(title)\n",
    "    all_texts.append(text)\n",
    "    #print(f\"Title: {title}\\nText: {text}...\\n\")\n",
    "    #print('#' * 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import editdistance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "\n",
    "    set1 = set(text1.split())\n",
    "    set2 = set(text2.split())\n",
    "    \n",
    "    return len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "\n",
    "    vectorizer = CountVectorizer().fit_transform([text1, text2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    cos_sim = cosine_similarity(vectors)\n",
    "    \n",
    "    return cos_sim[0][1]\n",
    "\n",
    "def edit_score(text1, text2):\n",
    "\n",
    "    return 1 - (editdistance.eval(text1, text2) / max(len(text1), len(text2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from ngram import NGram \n",
    "\n",
    "precision = 2\n",
    "threshold = .95\n",
    "\n",
    "def compute_metrics_for_articles(table, article_number, journal, article_type, manual, scraped, n_title, n_text):\n",
    "    \n",
    "    ngram_similarity = NGram.compare(manual, scraped, N=n_title) if article_type == 'Title' else NGram.compare(manual, scraped, N=n_text)\n",
    "    \n",
    "    edit_dist = editdistance.eval(manual, scraped)\n",
    "    edit_sim = edit_score(manual, scraped)\n",
    "\n",
    "    cos_sim = cosine_sim(manual, scraped)\n",
    "    \n",
    "    avg_similarity = (ngram_similarity + edit_sim) / 2\n",
    "    #avg_similarity = (ngram_similarity + edit_sim + cos_sim) / 3\n",
    "    \n",
    "    mark = 'X' if avg_similarity >= threshold else '-'\n",
    "\n",
    "    table.append([\n",
    "        article_number,\n",
    "        journal,\n",
    "        article_type,\n",
    "        ngram_similarity,\n",
    "        f'{edit_dist} ({edit_sim:.{precision}f})',\n",
    "        #cos_sim,\n",
    "        avg_similarity,\n",
    "        mark\n",
    "    ])\n",
    "\n",
    "    return avg_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "def get_journal_name(url):\n",
    "\n",
    "    second_level_domains = ['com.cn', 'co.uk', 'org.cn', 'net.cn', 'fr', 'de', 'es']\n",
    "    \n",
    "    parsed_url = urlparse(url)\n",
    "    domain_parts = parsed_url.netloc.split('.')\n",
    "    \n",
    "    if len(domain_parts) > 2 and '.'.join(domain_parts[-2:]) in second_level_domains:\n",
    "        return domain_parts[-3]\n",
    "\n",
    "    elif len(domain_parts) > 2:\n",
    "        return domain_parts[-2]\n",
    "        \n",
    "    else:\n",
    "        return domain_parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_similarity_results(table):\n",
    "    \n",
    "    headers = [\n",
    "        'Article #', \n",
    "        'Journal Name', \n",
    "        'Type', \n",
    "        'N-gram Similarity', \n",
    "        'Edit Distance (Score)', \n",
    "        #'Cosine Similarity',\n",
    "        'Combined Syntaxic Similarity (CSS)', \n",
    "        f'CSS > {threshold}', \n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        tabulate(\n",
    "            table, \n",
    "            headers=headers, \n",
    "            tablefmt='grid', \n",
    "            floatfmt=f'.{precision}f', \n",
    "            colalign=('center','center', 'center', 'center', 'center', 'center', 'center')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('text-mining-articles-scraping - Feuille 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n for titles (n-grams): 1\n",
      "Best n for texts (n-grams): 1\n",
      "Average CSS over all titles: 0.86\n",
      "Average CSS over all texts: 0.77\n",
      "\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|  Article #  |  Journal Name  |  Type   |  N-gram Similarity  |  Edit Distance (Score)  |  Combined Syntaxic Similarity (CSS)  |  CSS > 0.95  |\n",
      "+=============+================+=========+=====================+=========================+======================================+==============+\n",
      "|      1      |    nytimes     |  Title  |        0.00         |        71 (0.00)        |                 0.00                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      1      |    nytimes     | Content |        0.00         |       7580 (0.00)       |                 0.00                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      2      |      faz       |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      2      |      faz       | Content |        0.19         |       844 (0.15)        |                 0.17                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      3      |   chinatoday   |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      3      |   chinatoday   | Content |        0.96         |       204 (0.96)        |                 0.96                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      4      |     elpais     |  Title  |        0.69         |        39 (0.49)        |                 0.59                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      4      |     elpais     | Content |        0.92         |       1573 (0.86)       |                 0.89                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      5      |   insatiable   |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      5      |   insatiable   | Content |        0.94         |       360 (0.94)        |                 0.94                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      6      |      actu      |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      6      |      actu      | Content |        0.91         |       571 (0.83)        |                 0.87                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      7      | lesnumeriques  |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      7      | lesnumeriques  | Content |        0.83         |       693 (0.71)        |                 0.77                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      8      |   lebigdata    |  Title  |        0.54         |        41 (0.47)        |                 0.51                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      8      |   lebigdata    | Content |        0.87         |       431 (0.87)        |                 0.87                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      9      |     orange     |  Title  |        0.90         |        13 (0.90)        |                 0.90                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      9      |     orange     | Content |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     10      |     cbnews     |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     10      |     cbnews     | Content |        1.00         |        1 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     11      |   tradingsat   |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     11      |   tradingsat   | Content |        0.98         |       104 (0.98)        |                 0.98                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     12      |  journaldunet  |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     12      |  journaldunet  | Content |        0.22         |       4725 (0.22)       |                 0.22                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     13      |    lemonde     |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     13      |    lemonde     | Content |        0.85         |       550 (0.83)        |                 0.84                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     14      |    lemonde     |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     14      |    lemonde     | Content |        0.94         |       501 (0.84)        |                 0.89                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     15      |    lemonde     |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     15      |    lemonde     | Content |        0.89         |       637 (0.77)        |                 0.83                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     16      |    lemonde     |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     16      |    lemonde     | Content |        0.93         |       433 (0.92)        |                 0.93                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     17      |    lefigaro    |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     17      |    lefigaro    | Content |        1.00         |        18 (1.00)        |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     18      |    lefigaro    |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     18      |    lefigaro    | Content |        1.00         |        5 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     19      |    lefigaro    |  Title  |        0.86         |        24 (0.81)        |                 0.84                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     19      |    lefigaro    | Content |        0.80         |       1415 (0.74)       |                 0.77                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     20      |  francetvinfo  |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     20      |  francetvinfo  | Content |        0.92         |       251 (0.92)        |                 0.92                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     21      |  francetvinfo  |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     21      |  francetvinfo  | Content |        0.96         |       164 (0.96)        |                 0.96                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     22      |   liberation   |  Title  |        0.88         |        13 (0.88)        |                 0.88                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     22      |   liberation   | Content |        1.00         |        2 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     23      |    nytimes     |  Title  |        0.00         |        57 (0.00)        |                 0.00                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|     23      |    nytimes     | Content |        0.00         |       5418 (0.00)       |                 0.00                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "journals = df['url'].apply(get_journal_name).tolist()\n",
    "titles = df['title'].tolist()\n",
    "contents = df['content'].tolist()\n",
    "\n",
    "title_scores_by_n = {n: [] for n in range(1, 10)}\n",
    "text_scores_by_n = {n: [] for n in range(1, 10)}\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    if i < len(all_titles) and i < len(all_texts):\n",
    "        \n",
    "        journal = journals[i]\n",
    "        title = titles[i]\n",
    "        content = contents[i]\n",
    "\n",
    "        for n in range(1, 10):\n",
    "            title_score = compute_metrics_for_articles([], i+1, journal, 'Title', title, all_titles[i], n_title=n, n_text=10)\n",
    "            title_scores_by_n[n].append(title_score)\n",
    "            \n",
    "            text_score = compute_metrics_for_articles([], i+1, journal, 'Content', content, all_texts[i], n_title=1, n_text=n)\n",
    "            text_scores_by_n[n].append(text_score)\n",
    "\n",
    "av_title_scores = {n: mean(scores) for n, scores in title_scores_by_n.items()}\n",
    "n_title_opt = max(av_title_scores, key=av_title_scores.get)\n",
    "print(f'Best n for titles (n-grams): {n_title_opt}')\n",
    "\n",
    "av_text_scores = {n: mean(scores) for n, scores in text_scores_by_n.items()}\n",
    "n_text_opt = max(av_text_scores, key=av_text_scores.get)\n",
    "print(f'Best n for texts (n-grams): {n_text_opt}')\n",
    "\n",
    "table = []\n",
    "final_title_scores = []\n",
    "final_text_scores = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    if i < len(all_titles) and i < len(all_texts):\n",
    "        journal = journals[i]\n",
    "        title = titles[i]\n",
    "        content = contents[i]\n",
    "        \n",
    "        final_title_scores.append(compute_metrics_for_articles(table, i+1, journal, 'Title', title, all_titles[i], n_title=n_title_opt, n_text=n_text_opt))\n",
    "        final_text_scores.append(compute_metrics_for_articles(table, i+1, journal, 'Content', content, all_texts[i], n_title=n_title_opt, n_text=n_text_opt))\n",
    "\n",
    "print(f\"Average CSS over all titles: {mean(final_title_scores):.{precision}f}\")\n",
    "print(f\"Average CSS over all texts: {mean(final_text_scores):.{precision}f}\\n\")\n",
    "print_similarity_results(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better approach for the 6 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('results.csv')\n",
    "all_titles = new_df['title']\n",
    "all_texts = new_df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n for titles (n-grams): 1\n",
      "Best n for texts (n-grams): 1\n",
      "Average CSS over all titles: 0.88\n",
      "Average CSS over all texts: 0.78\n",
      "\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|  Article #  |  Journal Name  |  Type   |  N-gram Similarity  |  Edit Distance (Score)  |  Combined Syntaxic Similarity (CSS)  |  CSS > 0.95  |\n",
      "+=============+================+=========+=====================+=========================+======================================+==============+\n",
      "|      1      |    nytimes     |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      1      |    nytimes     | Content |        0.89         |       884 (0.88)        |                 0.88                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      2      |      faz       |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      2      |      faz       | Content |        0.16         |       861 (0.13)        |                 0.15                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      3      |   chinatoday   |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      3      |   chinatoday   | Content |        0.96         |       204 (0.96)        |                 0.96                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      4      |     elpais     |  Title  |        0.69         |        39 (0.49)        |                 0.59                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      4      |     elpais     | Content |        0.86         |       1672 (0.85)       |                 0.86                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      5      |   insatiable   |  Title  |        0.72         |        15 (0.72)        |                 0.72                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      5      |   insatiable   | Content |        0.94         |       380 (0.94)        |                 0.94                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      6      |      actu      |  Title  |        1.00         |        0 (1.00)         |                 1.00                 |      X       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n",
      "|      6      |      actu      | Content |        0.92         |       397 (0.87)        |                 0.90                 |      -       |\n",
      "+-------------+----------------+---------+---------------------+-------------------------+--------------------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "journals = df['url'].apply(get_journal_name).tolist()\n",
    "titles = df['title'].tolist()\n",
    "contents = df['content'].tolist()\n",
    "\n",
    "title_scores_by_n = {n: [] for n in range(1, 10)}\n",
    "text_scores_by_n = {n: [] for n in range(1, 10)}\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    if i < len(all_titles) and i < len(all_texts):\n",
    "\n",
    "        journal = journals[i]\n",
    "        title = titles[i]\n",
    "        content = contents[i]\n",
    "\n",
    "        for n in range(1, 10):\n",
    "            \n",
    "            title_score = compute_metrics_for_articles([], i+1, journal, 'Title', title, all_titles[i], n_title=n, n_text=10)\n",
    "            title_scores_by_n[n].append(title_score)\n",
    "            \n",
    "            text_score = compute_metrics_for_articles([], i+1, journal, 'Content', content, all_texts[i], n_title=1, n_text=n)\n",
    "            text_scores_by_n[n].append(text_score)\n",
    "\n",
    "av_title_scores = {n: mean(scores) for n, scores in title_scores_by_n.items()}\n",
    "n_title_opt = max(av_title_scores, key=av_title_scores.get)\n",
    "print(f'Best n for titles (n-grams): {n_title_opt}')\n",
    "\n",
    "av_text_scores = {n: mean(scores) for n, scores in text_scores_by_n.items()}\n",
    "n_text_opt = max(av_text_scores, key=av_text_scores.get)\n",
    "print(f'Best n for texts (n-grams): {n_text_opt}')\n",
    "\n",
    "table = []\n",
    "final_title_scores = []\n",
    "final_text_scores = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    if i < len(all_titles) and i < len(all_texts):\n",
    "        \n",
    "        journal = journals[i]\n",
    "        title = titles[i]\n",
    "        content = contents[i]\n",
    "        \n",
    "        final_title_scores.append(compute_metrics_for_articles(table, i+1, journal, 'Title', title, all_titles[i], n_title=n_title_opt, n_text=n_text_opt))\n",
    "        final_text_scores.append(compute_metrics_for_articles(table, i+1, journal, 'Content', content, all_texts[i], n_title=n_title_opt, n_text=n_text_opt))\n",
    "\n",
    "print(f\"Average CSS over all titles: {mean(final_title_scores):.{precision}f}\")\n",
    "print(f\"Average CSS over all texts: {mean(final_text_scores):.{precision}f}\\n\")\n",
    "print_similarity_results(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
